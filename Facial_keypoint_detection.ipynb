{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial keypoint detection.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r8ywzNt5Ey7"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DJ-BL_K9mSr",
        "outputId": "fd954da8-fe4d-4590-e92f-93201273a77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "\n",
        "\n",
        "#os.environ['KAGGLE_USERNAME'] = \"mratel\" # username from the json file\n",
        "#os.environ['KAGGLE_KEY'] = \"2f57b686988cdfa59b5092b2ea2fc8be\" # key from the json file\n",
        "\n",
        "!kaggle competitions download -c facial-keypoints-detection\n",
        "\n",
        "train = pd.read_csv('training.zip')\n",
        "test = pd.read_csv('test.zip')\n",
        "lookid_data = pd.read_csv('IdLookupTable.csv')\n",
        "\n",
        "#train.T.isnull().any()\n",
        "\n",
        "train.fillna(method = 'ffill',inplace = True)\n",
        "\n",
        "imag = []\n",
        "for i in range(0,7049):\n",
        "    img = train['Image'][i].split(' ')\n",
        "    img = ['0' if x == '' else x for x in img]\n",
        "    imag.append(img)\n",
        "\n",
        "image_list = np.array(imag,dtype = 'float')\n",
        "\n",
        "X_train = image_list.reshape(-1,96,96,1)\n",
        "\n",
        "plt.imshow(X_train[0].reshape(96,96),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "training = train.drop('Image',axis = 1)\n",
        "\n",
        "y_train = []\n",
        "for i in range(0,7049):\n",
        "    y = training.iloc[i,:]\n",
        "\n",
        "    y_train.append(y)\n",
        "y_train = np.array(y_train,dtype = 'float')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c47fe21d0628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kaggle competitions download -c facial-keypoints-detection'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlookid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IdLookupTable.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddZpFRZa0r7W",
        "outputId": "b765f7e9-f4a2-41d2-e306-8e366649bf91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(30))\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihftFwsp8Fut"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(30))\n",
        "                        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKrldV0p0r4Q",
        "outputId": "5299bdd9-1b62-4db8-88ab-3dd2eed21d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OkZ8AKR0r0i",
        "outputId": "0628c429-bc39-4461-a1a5-d803f5f4a011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=3, patience=300), ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "model.fit(X_train, y_train, epochs = 30, batch_size = 256, validation_split = 0.2, callbacks=es)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 5639 samples, validate on 1410 samples\n",
            "Epoch 1/30\n",
            "5639/5639 [==============================] - 244s 43ms/step - loss: 736.3566 - mean_absolute_error: 19.8568 - val_loss: 184.6800 - val_mean_absolute_error: 10.7896\n",
            "Epoch 2/30\n",
            "5639/5639 [==============================] - 236s 42ms/step - loss: 151.5024 - mean_absolute_error: 8.6441 - val_loss: 101.4694 - val_mean_absolute_error: 8.1276\n",
            "Epoch 3/30\n",
            "5639/5639 [==============================] - 238s 42ms/step - loss: 120.2594 - mean_absolute_error: 7.6356 - val_loss: 196.7990 - val_mean_absolute_error: 11.6568\n",
            "Epoch 4/30\n",
            "5639/5639 [==============================] - 236s 42ms/step - loss: 81.5754 - mean_absolute_error: 6.5561 - val_loss: 451.7161 - val_mean_absolute_error: 18.1068\n",
            "Epoch 5/30\n",
            "5639/5639 [==============================] - 236s 42ms/step - loss: 74.5694 - mean_absolute_error: 6.3133 - val_loss: 119.1579 - val_mean_absolute_error: 8.8733\n",
            "Epoch 6/30\n",
            "5639/5639 [==============================] - 236s 42ms/step - loss: 60.1669 - mean_absolute_error: 5.8206 - val_loss: 72.5235 - val_mean_absolute_error: 6.6924\n",
            "Epoch 7/30\n",
            "5639/5639 [==============================] - 235s 42ms/step - loss: 54.7228 - mean_absolute_error: 5.5908 - val_loss: 70.1919 - val_mean_absolute_error: 6.5831\n",
            "Epoch 8/30\n",
            "5639/5639 [==============================] - 235s 42ms/step - loss: 50.4857 - mean_absolute_error: 5.3906 - val_loss: 82.6802 - val_mean_absolute_error: 7.2301\n",
            "Epoch 9/30\n",
            "5639/5639 [==============================] - 234s 41ms/step - loss: 47.8985 - mean_absolute_error: 5.2602 - val_loss: 25.8819 - val_mean_absolute_error: 3.8095\n",
            "Epoch 10/30\n",
            "5639/5639 [==============================] - 235s 42ms/step - loss: 47.2443 - mean_absolute_error: 5.2048 - val_loss: 69.8588 - val_mean_absolute_error: 6.8838\n",
            "Epoch 11/30\n",
            "5639/5639 [==============================] - 234s 41ms/step - loss: 71.3442 - mean_absolute_error: 6.4143 - val_loss: 16.2642 - val_mean_absolute_error: 3.0292\n",
            "Epoch 12/30\n",
            "5639/5639 [==============================] - 234s 42ms/step - loss: 45.5328 - mean_absolute_error: 5.1066 - val_loss: 38.7206 - val_mean_absolute_error: 5.0179\n",
            "Epoch 13/30\n",
            "5639/5639 [==============================] - 234s 41ms/step - loss: 36.6478 - mean_absolute_error: 4.5245 - val_loss: 34.6387 - val_mean_absolute_error: 4.8424\n",
            "Epoch 14/30\n",
            "5639/5639 [==============================] - 234s 41ms/step - loss: 34.4817 - mean_absolute_error: 4.3970 - val_loss: 18.2067 - val_mean_absolute_error: 3.1408\n",
            "Epoch 15/30\n",
            "5639/5639 [==============================] - 233s 41ms/step - loss: 39.1009 - mean_absolute_error: 4.6953 - val_loss: 25.5723 - val_mean_absolute_error: 4.0585\n",
            "Epoch 16/30\n",
            "5639/5639 [==============================] - 233s 41ms/step - loss: 30.0377 - mean_absolute_error: 4.0592 - val_loss: 76.9473 - val_mean_absolute_error: 7.7805\n",
            "Epoch 17/30\n",
            "5639/5639 [==============================] - 235s 42ms/step - loss: 36.7240 - mean_absolute_error: 4.5677 - val_loss: 76.2790 - val_mean_absolute_error: 7.4462\n",
            "Epoch 18/30\n",
            "5639/5639 [==============================] - 239s 42ms/step - loss: 34.6823 - mean_absolute_error: 4.4358 - val_loss: 47.0988 - val_mean_absolute_error: 5.7391\n",
            "Epoch 19/30\n",
            "5639/5639 [==============================] - 237s 42ms/step - loss: 25.2300 - mean_absolute_error: 3.7577 - val_loss: 50.7773 - val_mean_absolute_error: 6.1985\n",
            "Epoch 20/30\n",
            "5639/5639 [==============================] - 239s 42ms/step - loss: 22.2688 - mean_absolute_error: 3.4903 - val_loss: 10.5801 - val_mean_absolute_error: 2.3254\n",
            "Epoch 21/30\n",
            "5639/5639 [==============================] - 235s 42ms/step - loss: 20.8412 - mean_absolute_error: 3.3696 - val_loss: 26.2389 - val_mean_absolute_error: 4.0039\n",
            "Epoch 22/30\n",
            "5639/5639 [==============================] - 238s 42ms/step - loss: 23.2710 - mean_absolute_error: 3.5475 - val_loss: 26.7454 - val_mean_absolute_error: 4.1182\n",
            "Epoch 23/30\n",
            "5639/5639 [==============================] - 235s 42ms/step - loss: 18.1430 - mean_absolute_error: 3.0660 - val_loss: 44.5649 - val_mean_absolute_error: 5.7653\n",
            "Epoch 24/30\n",
            "5639/5639 [==============================] - 234s 41ms/step - loss: 18.8071 - mean_absolute_error: 3.1314 - val_loss: 21.3307 - val_mean_absolute_error: 3.7354\n",
            "Epoch 25/30\n",
            "5639/5639 [==============================] - 234s 42ms/step - loss: 30.3360 - mean_absolute_error: 3.6137 - val_loss: 82.8999 - val_mean_absolute_error: 8.0648\n",
            "Epoch 26/30\n",
            "5639/5639 [==============================] - 234s 42ms/step - loss: 28.1889 - mean_absolute_error: 3.6302 - val_loss: 54.3762 - val_mean_absolute_error: 6.5005\n",
            "Epoch 27/30\n",
            "5639/5639 [==============================] - 234s 42ms/step - loss: 19.7295 - mean_absolute_error: 3.1117 - val_loss: 26.3076 - val_mean_absolute_error: 4.1789\n",
            "Epoch 28/30\n",
            "5639/5639 [==============================] - 233s 41ms/step - loss: 18.9744 - mean_absolute_error: 3.1501 - val_loss: 13.4479 - val_mean_absolute_error: 2.7490\n",
            "Epoch 29/30\n",
            "5639/5639 [==============================] - 233s 41ms/step - loss: 19.6000 - mean_absolute_error: 3.1007 - val_loss: 43.9589 - val_mean_absolute_error: 5.7586\n",
            "Epoch 30/30\n",
            "5639/5639 [==============================] - 235s 42ms/step - loss: 21.6040 - mean_absolute_error: 3.2887 - val_loss: 46.0851 - val_mean_absolute_error: 5.9449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f8da7b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8gJQgDjKU04"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuedrFnI0rqu"
      },
      "source": [
        "# Prédiction et submission\n",
        "\n",
        "#preparing test data\n",
        "timag = []\n",
        "for i in range(0,1783):\n",
        "    timg = test['Image'][i].split(' ')\n",
        "    timg = ['0' if x == '' else x for x in timg]\n",
        "    \n",
        "    timag.append(timg)\n",
        "\n",
        "timage_list = np.array(timag,dtype = 'float')\n",
        "X_test = timage_list.reshape(-1,96,96,1) \n",
        "\n",
        "#On charge le meilleur modèle enregistré\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "lookid_data = pd.read_csv('IdLookupTable.csv')\n",
        "lookid_list = list(lookid_data['FeatureName'])\n",
        "imageID = list(lookid_data['ImageId']-1)\n",
        "pre_list = list(pred)\n",
        "\n",
        "rowid = lookid_data['RowId']\n",
        "rowid=list(rowid)\n",
        "\n",
        "feature = []\n",
        "for f in list(lookid_data['FeatureName']):\n",
        "    feature.append(lookid_list.index(f))\n",
        "\n",
        "\n",
        "preded = []\n",
        "for x,y in zip(imageID,feature):\n",
        "    preded.append(pre_list[x][y])\n",
        "\n",
        "\n",
        "\n",
        "rowid = pd.Series(rowid,name = 'RowId')\n",
        "\n",
        "loc = pd.Series(preded,name = 'Location')\n",
        "\n",
        "submission = pd.concat([rowid,loc],axis = 1)\n",
        "\n",
        "submission.to_csv('face_key_detection_submission.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}